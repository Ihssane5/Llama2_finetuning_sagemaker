
# Introducing Generative AI with AWS

## Project Overview
This project is part of the "Introducing Generative AI with AWS" course. The primary objective is to fine-tune the Meta LLaMA 2 (meta-textgeneration-llama-2-7b) on a medical dataset to create a domain-specific language model.

## Model
**Model Name:** meta-textgeneration-llama-2-7b  
**Framework:** AWS  
**Objective:** Fine-tune the LLM to specialize in medical data, enhancing its capabilities in generating accurate and relevant medical text.

## Dataset
**Dataset Name:** medicalDataset.txt  
**Description:** The dataset comprises a comprehensive collection of medical texts, including research papers, clinical notes, and medical literature.

## Training
**Environment:** AWS SageMaker  
**Steps:**
1. Preprocessing the medical dataset.
2. Setting up the AWS environment.
3. Fine-tuning the LLM on the dataset.
4. Evaluating model performance.

## Report
A detailed report on the training and fine-tuning processes is included in the repository.

## Results
**Observations:** the finetuning process has a significant impact on the pretrained model performance on the medical domains.

## Conclusion
This project successfully demonstrates the process of fine-tuning a language model on a specialized dataset, showcasing its enhanced capabilities in generating domain-specific text.
